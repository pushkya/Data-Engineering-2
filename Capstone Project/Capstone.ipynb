{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# ETL pipeline for analysing immigration behaviours and effects of temperature in selecting destination \n",
    "\n",
    "## Data Engineering Capstone Project\n",
    "\n",
    "This project was made using Spark in order to make a datawarehouse in parquet file format that reflects immigration and temperatue data in US. It's used a star schema with a facts table an dimensional tables.\n",
    "The datawarehouse will then be used to answer questions regarding immigration behavior to location tempatures.\n",
    "\n",
    "The project follows the follow steps:\n",
    "- Step 1: Scope the Project and Gather Data\n",
    "- Step 2: Explore and Assess the Data\n",
    "- Step 3: Define the Data Model\n",
    "- Step 4: Run ETL to Model the Data\n",
    "- Step 5: Complete Project Write Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession, SQLContext \n",
    "from pyspark.sql.types import DateType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf, rand\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "import configparser\n",
    "import psycopg2\n",
    "from convert_sas_to_df import convert\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import date_add as d_add\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Build spark session\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step 1: Scope the Project and Gather Data\n",
    "\n",
    "## Scope\n",
    "\n",
    "This project will pull data from all sources and create fact and dimension tables to show movement of immigration and to determine if temperature affects the selection of destination cities for immigration.\n",
    "\n",
    "## Describe and Gather Data\n",
    "\n",
    "- **U.S. City Demographic Data (city_demo):** comes from OpenSoft and includes data by city, state, age, population, veteran status and race.\n",
    "\n",
    "- **I94 Immigration Data (immigration_data):** comes from the US National Tourism and Trade Office and includes details on incoming immigrants and their ports of entry.\n",
    "\n",
    "- **Airport Code Table (airport):** comes from datahub.io and includes airport codes and corresponding cities.\n",
    "\n",
    "- **Countries (country):** comes from I94_SAS_Labels_Descriptions.SAS\n",
    "\n",
    "- **Visas (visa):** comes from I94_SAS_Labels_Descriptions.SAS\n",
    "\n",
    "- **Immigrant Entry Mode (mode):** comes from I94_SAS_Labels_Descriptions.SAS\n",
    "\n",
    "- **Address(address):** comes from I94_SAS_Labels_Descriptions.SAS\n",
    "\n",
    "- **Temperature Data(temp_data)**: comes from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## View Dataset schema and rows in raw format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n",
      "None\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "|5748519.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     M|  null|     DL|9.495640653E10|00040|      B1|\n",
      "|5748520.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     F|  null|     DL|9.495645143E10|00040|      B1|\n",
      "|5748521.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  28.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1988.0|10292016|     M|  null|     DL|9.495638813E10|00040|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I94 immigration_data\n",
    "immigration_data = spark.read.parquet(\"sas_data\")\n",
    "print(immigration_data.printSchema())\n",
    "immigration_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n",
      "None\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#City Demographics data\n",
    "city_demo = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \";\").load(\"us-cities-demographics.csv\")\n",
    "print(city_demo.printSchema())\n",
    "city_demo.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n",
      "None\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Airport data\n",
    "airport = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"airport-codes_csv.csv\")\n",
    "print(airport.printSchema())\n",
    "airport.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n",
      "None\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#City Temperature data\n",
    "temp_data = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"GlobalLandTemperaturesByCity.csv\")\n",
    "print(temp_data.printSchema())\n",
    "temp_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Extracting data from the label.sas file\n",
    "convert('I94_SAS_Labels_Descriptions.SAS', 'i94cntyl', ['country_code', 'country'], 'Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n",
      "None\n",
      "+---+------------+--------------------+\n",
      "|_c0|country_code|             country|\n",
      "+---+------------+--------------------+\n",
      "|  0|         582|MEXICO Air Sea, a...|\n",
      "|  1|         236|         AFGHANISTAN|\n",
      "|  2|         101|             ALBANIA|\n",
      "|  3|         316|             ALGERIA|\n",
      "|  4|         102|             ANDORRA|\n",
      "+---+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Country data\n",
    "country = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"Country.csv\")\n",
    "print(country.drop('_c0').printSchema())\n",
    "country.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "convert('I94_SAS_Labels_Descriptions.SAS', 'I94VISA', ['visa_code', 'visa'], 'Visa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- visa_code: string (nullable = true)\n",
      " |-- visa: string (nullable = true)\n",
      "\n",
      "None\n",
      "+---+---------+--------+\n",
      "|_c0|visa_code|    visa|\n",
      "+---+---------+--------+\n",
      "|  0|        1|Business|\n",
      "|  1|        2|Pleasure|\n",
      "|  2|        3| Student|\n",
      "+---+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Visa Data\n",
    "visa = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"Visa.csv\")\n",
    "print(visa.drop('_c0').printSchema())\n",
    "visa.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "convert('I94_SAS_Labels_Descriptions.SAS', 'I94MODE', ['mode_code', 'mode'], 'Mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mode_code: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      "\n",
      "None\n",
      "+---+---------+------------+\n",
      "|_c0|mode_code|        mode|\n",
      "+---+---------+------------+\n",
      "|  0|        1|         Air|\n",
      "|  1|        2|         Sea|\n",
      "|  2|        3|        Land|\n",
      "|  3|        9|Not reported|\n",
      "+---+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Mode data\n",
    "mode = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"Mode.csv\")\n",
    "print(mode.drop('_c0').printSchema())\n",
    "mode.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "convert('I94_SAS_Labels_Descriptions.SAS', 'I94ADDR', ['addr_code', 'address'],'address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- addr_code: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      "\n",
      "None\n",
      "+---+---------+----------+\n",
      "|_c0|addr_code|   address|\n",
      "+---+---------+----------+\n",
      "|  0|       AL|   ALABAMA|\n",
      "|  1|       AK|    ALASKA|\n",
      "|  2|       AZ|   ARIZONA|\n",
      "|  3|       AR|  ARKANSAS|\n",
      "|  4|       CA|CALIFORNIA|\n",
      "+---+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Address data\n",
    "address = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"address.csv\")\n",
    "print(address.drop('_c0').printSchema())\n",
    "address.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step-2 Explore and Assess Dataset\n",
    "\n",
    "This step involves preprocessing of datasets which includes:\n",
    "- Renaming the columns \n",
    "- Changing datatypes of columns\n",
    "- Dropping duplicates\n",
    "- Dropping/filling null values\n",
    "- Put correct formats in dates and select only important columns\n",
    "- Generating new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### **Immigration dataset:** \n",
    "Rename columns with understandable names. Put correct formats in dates and select only important columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_data = immigration_data \\\n",
    "            .withColumn(\"cic_id\", col(\"cicid\").cast(\"integer\")) \\\n",
    "            .drop(\"cicid\") \\\n",
    "            .withColumnRenamed(\"i94addr\", \"code_state\") \\\n",
    "            .withColumnRenamed(\"i94port\", \"code_port\") \\\n",
    "            .withColumn(\"code_visa\", col(\"i94visa\").cast(\"integer\")) \\\n",
    "            .drop(\"i94visa\") \\\n",
    "            .withColumn(\"code_mode\", col(\"i94mode\").cast(\"integer\")) \\\n",
    "            .drop(\"i94mode\") \\\n",
    "            .withColumn(\"code_country_origin\", col(\"i94res\").cast(\"integer\")) \\\n",
    "            .drop(\"i94res\") \\\n",
    "            .withColumn(\"code_country_cit\", col(\"i94cit\").cast(\"integer\")) \\\n",
    "            .drop(\"i94cit\") \\\n",
    "            .withColumn(\"year\", col(\"i94yr\").cast(\"integer\")) \\\n",
    "            .drop(\"i94yr\") \\\n",
    "            .withColumn(\"month\", col(\"i94mon\").cast(\"integer\")) \\\n",
    "            .drop(\"i94mon\") \\\n",
    "            .withColumn(\"bird_year\", col(\"biryear\").cast(\"integer\")) \\\n",
    "            .drop(\"biryear\") \\\n",
    "            .withColumn(\"age\", col(\"i94bir\").cast(\"integer\")) \\\n",
    "            .drop(\"i94bir\") \\\n",
    "            .withColumn(\"counter\", col(\"count\").cast(\"integer\")) \\\n",
    "            .drop(\"count\") \\\n",
    "            .withColumn(\"data_base_sas\", F.to_date(F.lit(\"01/01/1960\"), \"MM/dd/yyyy\")) \\\n",
    "            .withColumn(\"arrival_date\", F.expr(\"date_add(data_base_sas, arrdate)\")) \\\n",
    "            .withColumn(\"departure_date\", F.expr(\"date_add(data_base_sas, depdate)\")) \\\n",
    "            .drop(\"data_base_sas\", \"arrdate\", \"depdate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+--------+-------+--------+------+-------+--------------+-----+--------+---------+---------+-------------------+----------------+----+-----+---------+---+-------+------------+--------------+\n",
      "| cic_id|code_port|code_state|visapost|matflag| dtaddto|gender|airline|        admnum|fltno|visatype|code_visa|code_mode|code_country_origin|code_country_cit|year|month|bird_year|age|counter|arrival_date|departure_date|\n",
      "+-------+---------+----------+--------+-------+--------+------+-------+--------------+-----+--------+---------+---------+-------------------+----------------+----+-----+---------+---+-------+------------+--------------+\n",
      "|5748517|      LOS|        CA|     SYD|      M|10292016|     F|     QF|9.495387003E10|00011|      B1|        1|        1|                438|             245|2016|    4|     1976| 40|      1|  2016-04-30|    2016-05-08|\n",
      "|5748518|      LOS|        NV|     SYD|      M|10292016|     F|     VA|9.495562283E10|00007|      B1|        1|        1|                438|             245|2016|    4|     1984| 32|      1|  2016-04-30|    2016-05-17|\n",
      "|5748519|      LOS|        WA|     SYD|      M|10292016|     M|     DL|9.495640653E10|00040|      B1|        1|        1|                438|             245|2016|    4|     1987| 29|      1|  2016-04-30|    2016-05-08|\n",
      "|5748520|      LOS|        WA|     SYD|      M|10292016|     F|     DL|9.495645143E10|00040|      B1|        1|        1|                438|             245|2016|    4|     1987| 29|      1|  2016-04-30|    2016-05-14|\n",
      "|5748521|      LOS|        WA|     SYD|      M|10292016|     M|     DL|9.495638813E10|00040|      B1|        1|        1|                438|             245|2016|    4|     1988| 28|      1|  2016-04-30|    2016-05-14|\n",
      "|5748522|      HHW|        HI|     ACK|      M|10292016|     M|     NZ|9.498180283E10|00010|      B2|        2|        1|                464|             245|2016|    4|     1959| 57|      1|  2016-04-30|    2016-05-05|\n",
      "|5748523|      HHW|        HI|     ACK|      M|10292016|     F|     NZ|9.497968993E10|00010|      B2|        2|        1|                464|             245|2016|    4|     1950| 66|      1|  2016-04-30|    2016-05-12|\n",
      "|5748524|      HHW|        HI|     ACK|      M|10292016|     F|     NZ|9.497974673E10|00010|      B2|        2|        1|                464|             245|2016|    4|     1975| 41|      1|  2016-04-30|    2016-05-12|\n",
      "|5748525|      HOU|        FL|     ACK|      M|10292016|     M|     NZ|9.497324663E10|00028|      B2|        2|        1|                464|             245|2016|    4|     1989| 27|      1|  2016-04-30|    2016-05-07|\n",
      "|5748526|      LOS|        CA|     ACK|      M|10292016|     F|     NZ|9.501354793E10|00002|      B2|        2|        1|                464|             245|2016|    4|     1990| 26|      1|  2016-04-30|    2016-05-07|\n",
      "+-------+---------+----------+--------+-------+--------+------+-------+--------------+-----+--------+---------+---------+-------------------+----------------+----+-----+---------+---+-------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_data = immigration_data.select(col(\"cic_id\"), col(\"code_port\"), col(\"code_state\"), col(\"visapost\"), col(\"matflag\"),\n",
    "                                  col(\"dtaddto\") \\\n",
    "                                  , col(\"gender\"), col(\"airline\"), col(\"admnum\"), col(\"fltno\"), col(\"visatype\"),\n",
    "                                  col(\"code_visa\"), col(\"code_mode\") \\\n",
    "                                  , col(\"code_country_origin\"), col(\"code_country_cit\"), col(\"year\"), col(\"month\"),\n",
    "                                  col(\"bird_year\") \\\n",
    "                                  , col(\"age\"), col(\"counter\"), col(\"arrival_date\"), col(\"departure_date\"))\n",
    "immigration_data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### **Demographics dataset:** \n",
    "Fill null values with 0 and grouping by city and state and pivot Race in diferent columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "city_demo = city_demo.groupBy(col(\"City\"), col(\"State\"), col(\"Median Age\"), col(\"Male Population\"),\n",
    "                                     col(\"Female Population\") \\\n",
    "                                     , col(\"Total Population\"), col(\"Number of Veterans\"), col(\"Foreign-born\"),\n",
    "                                     col(\"Average Household Size\") \\\n",
    "                                     , col(\"State Code\")).pivot(\"Race\").agg(_sum(\"count\").cast(\"integer\")) \\\n",
    "            .fillna({\"American Indian and Alaska Native\": 0,\n",
    "                     \"Asian\": 0,\n",
    "                     \"Black or African-American\": 0,\n",
    "                     \"Hispanic or Latino\": 0,\n",
    "                     \"White\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "city_demo = city_demo.withColumnRenamed('Median Age', 'Median_age').withColumnRenamed('Male Population' , 'Male_population')\\\n",
    ".withColumnRenamed('Female Population', 'Female_population').withColumnRenamed('Total Population', 'Total_population')\\\n",
    ".withColumnRenamed('Number of Veterans', 'Number_of_veterans').withColumnRenamed('Average Household Size', 'Average_Household_Size')\\\n",
    ".withColumnRenamed('State Code', 'State_Code').withColumnRenamed('American Indian and Alaska Native', 'American_Indian_and_Alaska_Native')\\\n",
    ".withColumnRenamed('Black or African-American', 'Black_or_African-American').withColumnRenamed('Hispanic or Latino', 'Hispanic_or_Latino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|         City|         State|Median_age|Male_population|Female_population|Total_population|Number_of_veterans|Foreign-born|Average_Household_Size|State_Code|American_Indian_and_Alaska_Native|Asian|Black_or_African-American|Hispanic_or_Latino| White|\n",
      "+-------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|       Skokie|      Illinois|      43.4|          31382|            33437|           64819|              1066|       27424|                  2.78|        IL|                                0|20272|                     4937|              6590| 40642|\n",
      "|    Charlotte|North Carolina|      34.3|         396646|           430475|          827121|             36046|      128897|                  2.52|        NC|                             8746|55399|                   301568|            113731|446795|\n",
      "|   Manchester| New Hampshire|      37.3|          54845|            55378|          110223|              5473|       14506|                   2.4|        NH|                              558| 4304|                     6896|             11962|100108|\n",
      "|        Chico|    California|      29.9|          46168|            44168|           90336|              4519|        8425|                   2.5|        CA|                             2766| 6101|                     3164|             15578| 80467|\n",
      "|Silver Spring|      Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|                             1084| 8841|                    21330|             25924| 37756|\n",
      "+-------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city_demo.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### **Airport dataset:** \n",
    "Extract iso regions and cast as float elevation feet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport = airport \\\n",
    "            .where(col(\"type\").isin(\"large_airport\", \"medium_airport\", \"small_airport\")) \\\n",
    "            .withColumn(\"iso_region\", F.substring(col(\"iso_region\"), 4, 2)) \\\n",
    "            .withColumn(\"elevation_ft\", col(\"elevation_ft\").cast(\"float\")).dropDuplicates().drop('continent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "| 05IA|small_airport|        Spotts Field|      1155.0|         US|        IA|Nora Springs|    05IA|     null|      05IA|-93.0682983398437...|\n",
      "| 0LS9|small_airport|   Huenefeld Airport|        72.0|         US|        LA|      Monroe|    0LS9|     null|      0LS9|-91.9821014404296...|\n",
      "| 0NY7|small_airport|Murphys Landing S...|       940.0|         US|        NY|       Perth|    0NY7|     null|      0NY7|-74.1843032836914...|\n",
      "| 0TX8|small_airport|       Jacobia Field|       570.0|         US|        TX|  Greenville|    0TX8|     null|      0TX8|-96.0432968139648...|\n",
      "| 0XS8|small_airport|Dunbar Ranch Airport|       958.0|         US|        TX|    Spofford|    0XS8|     null|      0XS8|-100.375, 29.0760...|\n",
      "+-----+-------------+--------------------+------------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### **Temperature dataset:** \n",
    "Generating city_code column from city column and droppping duplicates and null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_data = temp_data.dropDuplicates(['City', 'Country'])\n",
    "temp_data = temp_data.filter(temp_data.AverageTemperature != 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "re_obj = re.compile(r'\\'(.*)\\'.*\\'(.*)\\'')\n",
    "valid_code = {}\n",
    "with open('i94port.txt') as f:\n",
    "     for line in f:\n",
    "        match = re_obj.search(line)\n",
    "        valid_code[match[1]]=[match[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf()\n",
    "def get_code_city(city):\n",
    "    '''\n",
    "    Input: City name\n",
    "    \n",
    "    Output: Corresponding i94port\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for key in valid_code:\n",
    "        if city.lower() in valid_code[key][0].lower():\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+--------+-------------+--------+---------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|    City|      Country|Latitude|Longitude|city_code|\n",
      "+----------+------------------+-----------------------------+--------+-------------+--------+---------+---------+\n",
      "|1852-07-01|            15.488|                        1.395|   Perth|    Australia|  31.35S|  114.97E|      PER|\n",
      "|1828-01-01|            -1.977|                        2.551| Seattle|United States|  47.42N|  121.97W|      SEA|\n",
      "|1743-11-01|             2.767|                        1.905|Hamilton|       Canada|  42.59N|   80.73W|      HAM|\n",
      "|1849-01-01| 7.399999999999999|                        2.699| Ontario|United States|  34.56N|  116.76W|      ONT|\n",
      "|1821-11-01|             2.322|                        2.375| Spokane|United States|  47.42N|  117.24W|      SPO|\n",
      "+----------+------------------+-----------------------------+--------+-------------+--------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_data = temp_data.withColumn(\"city_code\", get_code_city(temp_data.City))\n",
    "temp_data = temp_data.filter(temp_data.city_code != 'null')\n",
    "temp_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step 3: Define the Data Model\n",
    "\n",
    "#### 3.1 Conceptual Model\n",
    "\n",
    "##### Star Schema\n",
    "\n",
    "**Fact Table** - This will contain information from the I94 immigration data joined with the city temperature data on city_code and similarly other tables.\n",
    "\n",
    "fact_immigration:\n",
    "- cic_id: integer \n",
    "- code_port: string \n",
    "- code_state: string \n",
    "- visapost: string \n",
    "- matflag: string\n",
    "- dtaddto: string\n",
    "- gender: string\n",
    "- airline: string\n",
    "- admnum: double\n",
    "- fltno: string \n",
    "- visatype: string\n",
    "- code_visa: integer\n",
    "- code_mode: integer\n",
    "- code_country_origin: integer\n",
    "- code_country_cit: integer\n",
    "- year: integer\n",
    "- month: integer\n",
    "- bird_year: integer\n",
    "- age: integer\n",
    "- counter: integer\n",
    "- arrival_date: date\n",
    "- departure_date: date\n",
    "\n",
    "\n",
    "**Dimension Table** - This will contain events from the I94 immigration data.\n",
    "\n",
    "city_demo:\n",
    "- City: string \n",
    "- State: string \n",
    "- Median_age: string \n",
    "- Male_population: string \n",
    "- Female_population: string \n",
    "- Total_population: string \n",
    "- Number_of_veterans: string \n",
    "- Foreign-born: string \n",
    "- Average_Household_Size: string \n",
    "- State_Code: string \n",
    "- American_Indian_and_Alaska_Native: integer \n",
    "- Asian: integer \n",
    "- Black_or_African-American: integer \n",
    "- Hispanic_or_Latino: integer \n",
    "- White: integer \n",
    "\n",
    "\n",
    "airport:\n",
    "- ident: string \n",
    "- type: string \n",
    "- name: string \n",
    "- elevation_ft: float \n",
    "- iso_country: string \n",
    "- iso_region: string \n",
    "- municipality: string \n",
    "- gps_code: string \n",
    "- iata_code: string \n",
    "- local_code: string \n",
    "- coordinates: string\n",
    "\n",
    "\n",
    "country:\n",
    "- country_code: string \n",
    "- country: string \n",
    "\n",
    "\n",
    "visa:\n",
    "- visa_code: string\n",
    "- visa: string\n",
    "\n",
    "\n",
    "mode:\n",
    "- mode_code: string\n",
    "- mode: string\n",
    "\n",
    "\n",
    "address:\n",
    "- addr_code: string\n",
    "- address: string\n",
    "\n",
    "\n",
    "temp_data:\n",
    "- dt: string \n",
    "- AverageTemperature: string \n",
    "- AverageTemperatureUncertainty: string \n",
    "- City: string \n",
    "- Country: string \n",
    "- Latitude: string \n",
    "- Longitude: string \n",
    "- city_code: string \n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "Pipeline Steps:\n",
    "- Model data\n",
    " - Create star schema with one facts table and six dimension tables\n",
    " - Write fact table in a parquet file partition by arrival_date\n",
    " - Write dimension table in a parquet file partitioned by respective columns\n",
    " - Insert in fact table with dimension keys for integrity and consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step 4: Run Pipelines to Model the Data\n",
    "\n",
    "#### Create the data model\n",
    "\n",
    "Build the data pipelines to create the data model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Creating Facts table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fact_immigration = immigration_data\\\n",
    ".join(city_demo, immigration_data['code_state'] == city_demo['State_Code'], 'left_semi')\\\n",
    ".join(airport, immigration_data['code_port'] == airport['local_code'], 'left_semi')\\\n",
    ".join(country, immigration_data['code_country_origin'] == country['country_code'], 'left_semi')\\\n",
    ".join(visa, immigration_data['code_visa'] == visa['visa_code'], 'left_semi')\\\n",
    ".join(mode, immigration_data['code_mode'] == mode['mode_code'], 'left_semi')\\\n",
    ".join(address, immigration_data['code_state'] == address['addr_code'], 'left_semi')\\\n",
    ".join(temp_data, immigration_data['code_port'] == temp_data['city_code'], 'left_semi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Writing to parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fact_immigration.write.partitionBy('arrival_date').mode('overwrite').parquet('./parquet/fact_immigration.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "city_demo.write.partitionBy(\"State_Code\").mode('overwrite').parquet('./parquet/dimension_city_demo.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport.write.partitionBy(\"local_code\").mode('overwrite').parquet('./parquet/dimension_airport.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country.write.partitionBy('country_code').mode('overwrite').parquet('./parquet/dimension_country.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "visa.write.partitionBy('visa_code').mode('overwrite').parquet('./parquet/dimension_visa.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "mode.write.partitionBy('mode_code').mode('overwrite').parquet('./parquet/dimension_mode.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "address.write.partitionBy('addr_code').mode('overwrite').parquet('./parquet/dimension_address.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_data.write.partitionBy('year').mode('overwrite').parquet('./parquet/dimension_temperature.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    "- Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    "- Unit tests for the scripts to ensure they are doing the right thing\n",
    "- Source/Count checks to ensure completeness\n",
    "\n",
    "\n",
    "### Quality checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def qCheck(df, tabname):\n",
    "    '''\n",
    "    Input: Spark dataframe, name of Spark datafram\n",
    "    Output: Print outcome of data quality check\n",
    "    '''\n",
    "    res = df.count()\n",
    "    if res == 0:\n",
    "        print(\"Data quality check failed for {} with zero records\".format(tabname))\n",
    "    else:\n",
    "        print(\"Data quality check passed for {} with {} records\".format(tabname, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for Immigration_table with 1637289 records\n",
      "Data quality check passed for City_demo_table with 596 records\n",
      "Data quality check passed for Airport_table with 39142 records\n",
      "Data quality check passed for Country_table with 289 records\n",
      "Data quality check passed for Visa_table with 3 records\n",
      "Data quality check passed for Mode_table with 4 records\n",
      "Data quality check passed for Address_table with 55 records\n",
      "Data quality check passed for Temperature_table with 207 records\n"
     ]
    }
   ],
   "source": [
    "qCheck(fact_immigration, 'Immigration_table')\n",
    "qCheck(city_demo, 'City_demo_table')\n",
    "qCheck(airport, 'Airport_table')\n",
    "qCheck(country, 'Country_table')\n",
    "qCheck(visa, 'Visa_table')\n",
    "qCheck(mode, 'Mode_table')\n",
    "qCheck(address, 'Address_table')\n",
    "qCheck(temp_data, 'Temperature_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary\n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file.\n",
    "\n",
    "fact_immigration:\n",
    "- cic_id: integer - CIC id\n",
    "- code_port: string - Airport code \n",
    "- code_state: string - State code\n",
    "- visapost: string - Department of State where where Visa was issued\n",
    "- matflag: string - Match of arrival and departure records\n",
    "- dtaddto: string - Date to which admitted to U.S. \n",
    "- gender: string - Gender\n",
    "- airline: string - Airline code\n",
    "- admnum: double - Admission Number\n",
    "- fltno: string - Flight number of Airline used to arrive in U.S.\n",
    "- visatype: string -  Class of admission legally admitting the non-immigrant to temporarily stay in U.S\n",
    "- code_visa: integer - Visa code\n",
    "- code_mode: integer - Mode code\n",
    "- code_country_origin: integer - Country of origin code\n",
    "- code_country_cit: integer - City of origin code\n",
    "- year: integer - Year\n",
    "- month: integer - Month \n",
    "- bird_year: integer - Year of Birth\n",
    "- age: integer - Age\n",
    "- counter: integer  - Used for summary statistics\n",
    "- arrival_date: date - Arrival date\n",
    "- departure_date: date - Departure date\n",
    "\n",
    "\n",
    "**Dimension Table** - This will contain events from the I94 immigration data.\n",
    "\n",
    "city_demo:\n",
    "- City: string - City name\n",
    "- State: string - State name\n",
    "- Median_age: string - Median age\n",
    "- Male_population: string  - Male population per state\n",
    "- Female_population: string - Female population per state\n",
    "- Total_population: string - Total population per state\n",
    "- Number_of_veterans: string - Number of veterans\n",
    "- Foreign-born: string - Foreign born\n",
    "- Average_Household_Size: string - Average Household Size\n",
    "- State_Code: string - State code\n",
    "- American_Indian_and_Alaska_Native: integer - Belonging to this category \n",
    "- Asian: integer - Belonging to this category \n",
    "- Black_or_African-American: integer - Belonging to this category \n",
    "- Hispanic_or_Latino: integer -Belonging to this category \n",
    "- White: integer - Belonging to this category \n",
    "\n",
    "\n",
    "airport:\n",
    "- ident: string - Airport id\n",
    "- type: string - size of airport\n",
    "- name: string - Airport name\n",
    "- elevation_ft: float - elevation in feet\n",
    "- iso_country: string -  country \n",
    "- iso_region: string - region\n",
    "- municipality: string - municipality\n",
    "- gps_code: string - gps\n",
    "- iata_code: string - iata code\n",
    "- local_code: string - local code\n",
    "- coordinates: string - coordinates\n",
    "\n",
    "\n",
    "country:\n",
    "- country_code: string - country code \n",
    "- country: string - country\n",
    "\n",
    "\n",
    "visa:\n",
    "- visa_code: string - visa code\n",
    "- visa: string - type of visa\n",
    "\n",
    "\n",
    "mode:\n",
    "- mode_code: string - mode code\n",
    "- mode: string - type of mode\n",
    "\n",
    "\n",
    "address:\n",
    "- addr_code: string - address code\n",
    "- address: string - address\n",
    "\n",
    "\n",
    "temp_data:\n",
    "- dt: string - date\n",
    "- AverageTemperature: string  - average temperature  \n",
    "- AverageTemperatureUncertainty: string - average temperature uncertainity \n",
    "- City: string - City\n",
    "- Country: string - Country\n",
    "- Latitude: string - Latitude\n",
    "- Longitude: string - Longitude\n",
    "- city_code: string - city code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step 5: Complete Project Write Up\n",
    "\n",
    "- Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "    - For this project, I used Spark since it can easily handle multiple file formats (SAS, csv, etc) that contain large amounts of data. The data persisted in parquet files can scale to lots of terabytes without any problems. \n",
    "\n",
    "\n",
    "- Propose how often the data should be updated and why.\n",
    "    - The data should be updated every day because fact table is partitioned by arrival date.\n",
    "\n",
    "\n",
    "- Write a description of how you would approach the problem differently under the following scenarios:\n",
    "    - The data was increased by 100x.\n",
    "      - Spark can handle without any problem if data was increased by 100x \n",
    "    - The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "      - Apache airflow can be used to schedule this update\n",
    "    - The database needed to be accessed by 100+ people.\n",
    "      - Redshift can be used to store this data since it has auto-scaling capabilities and good read performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
